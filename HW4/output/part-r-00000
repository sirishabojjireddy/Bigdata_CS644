");	1
"WORDCOUNT");	1
ARGS).GETREMAININGARGS();	1
CON.WRITE(OUTPUTKEY	1
CON.WRITE(WORD	1
CONFIGURATION C=NEW CONFIGURATION();	1
CONTEXT CON) THROWS IOEXCEPTION	2
FILEINPUTFORMAT.ADDINPUTPATH(J	1
FILEOUTPUTFORMAT.SETOUTPUTPATH(J	1
FOR(INTWRITABLE VALUE : VALUES)	1
FOR(STRING WORD: WORDS )	1
IMPORT JAVA.IO.IOEXCEPTION;	1
IMPORT ORG.APACHE.HADOOP.CONF.CONFIGURATION;	1
IMPORT ORG.APACHE.HADOOP.FS.PATH;	1
IMPORT ORG.APACHE.HADOOP.IO.INTWRITABLE;	1
IMPORT ORG.APACHE.HADOOP.IO.LONGWRITABLE;	1
IMPORT ORG.APACHE.HADOOP.IO.TEXT;	1
IMPORT ORG.APACHE.HADOOP.MAPREDUCE.JOB;	1
IMPORT ORG.APACHE.HADOOP.MAPREDUCE.LIB.INPUT.FILEINPUTFORMAT;	1
IMPORT ORG.APACHE.HADOOP.MAPREDUCE.LIB.OUTPUT.FILEOUTPUTFORMAT;	1
IMPORT ORG.APACHE.HADOOP.MAPREDUCE.MAPPER;	1
IMPORT ORG.APACHE.HADOOP.MAPREDUCE.REDUCER;	1
IMPORT ORG.APACHE.HADOOP.UTIL.GENERICOPTIONSPARSER;	1
INPUT);	1
INT SUM = 0;	1
INTERRUPTEDEXCEPTION	2
INTWRITABLE	1
INTWRITABLE OUTPUTVALUE = NEW INTWRITABLE(1);	1
INTWRITABLE>	1
INTWRITABLE>{	1
ITERABLE<INTWRITABLE> VALUES	1
J.SETJARBYCLASS(WORDCOUNT.CLASS);	1
J.SETMAPPERCLASS(MAPFORWORDCOUNT.CLASS);	1
J.SETOUTPUTKEYCLASS(TEXT.CLASS);	1
J.SETOUTPUTVALUECLASS(INTWRITABLE.CLASS);	1
J.SETREDUCERCLASS(REDUCEFORWORDCOUNT.CLASS);	1
JOB J=NEW JOB(C	1
NEW INTWRITABLE(SUM));	1
OUTPUT);	1
OUTPUTVALUE);	1
PACKAGE PACKAGEDEMO;	1
PATH INPUT=NEW PATH(FILES[0]);	1
PATH OUTPUT=NEW PATH(FILES[1]);	1
PUBLIC CLASS WORDCOUNT {	1
PUBLIC STATIC CLASS MAPFORWORDCOUNT EXTENDS MAPPER<LONGWRITABLE	1
PUBLIC STATIC CLASS REDUCEFORWORDCOUNT EXTENDS REDUCER<TEXT	1
PUBLIC STATIC VOID MAIN(STRING [] ARGS) THROWS EXCEPTION	1
PUBLIC VOID MAP(LONGWRITABLE KEY	1
PUBLIC VOID REDUCE(TEXT WORD	1
STRING LINE = VALUE.TOSTRING();	1
STRING[] FILES=NEW GENERICOPTIONSPARSER(C	1
STRING[] WORDS=LINE.SPLIT("	1
SUM += VALUE.GET();	1
SYSTEM.EXIT(J.WAITFORCOMPLETION(TRUE)?0:1);	1
TEXT	3
TEXT OUTPUTKEY = NEW TEXT(WORD.TOUPPERCASE().TRIM());	1
TEXT VALUE	1
{	6
}	8
