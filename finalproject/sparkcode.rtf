{\rtf1\ansi\ansicpg1252\cocoartf1671\cocoasubrtf400
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;\f1\fnil\fcharset0 Menlo-Bold;}
{\colortbl;\red255\green255\blue255;\red127\green0\blue85;\red42\green0\blue255;\red63\green127\blue95;
}
{\*\expandedcolortbl;;\csgenericrgb\c49804\c0\c33333;\csgenericrgb\c16471\c0\c100000;\csgenericrgb\c24706\c49804\c37255;
}
\margl1440\margr1440\vieww33400\viewh18120\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs24 \cf0 package com.spark.hackathon\

\f1\b \cf2 import
\f0\b0 \cf0  org.apache.spark.sql.SparkSession\
case class Flight_Data1(Year: String, Month: String, DayofMonth: String, DayOfWeek: String, DepTime: String,\
    CRSDepTime: String, ArrTime: String, CRSArrTime: String, UniqueCarrier: String, \
    FlightNum: String, TailNum: String, ActualElapsedTime: String, CRSElapsedTime: String, \
    AirTime: String, ArrDelay: String, DepDelay: String, Origin: String, \
    Dest: String, Distance: String, TaxiIn: String, TaxiOut: String, Cancelled: String, \
    CancellationCode: String, Diverted: String, CarrierDelay: String, \
    WeatherDelay: String, NASDelay: String, SecurityDelay: String, LateAircraftDelay: String)\
\
object exercise2 \{\
  def main(args: Array[String]) \{\
   \
\
    val spark = SparkSession.builder().appName(\cf3 "Exercise2"\cf0 ).master(\cf3 "local[*]"\cf0 ).getOrCreate()\
\
    spark.sparkContext.setLogLevel(\cf3 "ERROR"\cf0 )\
    val Flight_Data_Load = spark.read.format(\cf3 "csv"\cf0 ).option(\cf3 "delimiter"\cf0 , \cf3 ","\cf0 ).option(\cf3 "header"\cf0 , \cf3 "true"\cf0 ).option(\cf3 "inferSchema"\cf0 , \cf3 "true"\cf0 ).load(\cf3 "file:///Users/SirishaBojjireddy/Document/courses/CS644_bigdata/Realtime_fleet_Spark_4/input/"\cf0 )\
    
\f1\b \cf2 import
\f0\b0 \cf0  spark.implicits._\
    \
    val Flight_Data_DF = Flight_Data_Load.toDF(\cf3 "Year"\cf0 , \cf3 "Month"\cf0 , \cf3 "DayofMonth"\cf0 , \cf3 "DayOfWeek"\cf0 , \cf3 "DepTime"\cf0 , \cf3 "CRSDepTime"\cf0 , \cf3 "ArrTime"\cf0 , \cf3 "CRSArrTime"\cf0 , \cf3 "UniqueCarrier"\cf0 , \cf3 "FlightNum"\cf0 , \cf3 "TailNum"\cf0 , \cf3 "ActualElapsedTime"\cf0 , \cf3 "CRSElapsedTime"\cf0 , \cf3 "AirTime"\cf0 , \cf3 "ArrDelay"\cf0 , \cf3 "DepDelay"\cf0 , \cf3 "Origin"\cf0 , \cf3 "Dest"\cf0 , \cf3 "Distance"\cf0 , \cf3 "TaxiIn"\cf0 , \cf3 "TaxiOut"\cf0 , \cf3 "Cancelled"\cf0 , \cf3 "CancellationCode"\cf0 , \cf3 "Diverted"\cf0 , \cf3 "CarrierDelay"\cf0 , \cf3 "WeatherDelay"\cf0 , \cf3 "NASDelay"\cf0 , \cf3 "SecurityDelay"\cf0 , \cf3 "LateAircraftDelay"\cf0 )\
    \cf4 //*********\ul Dataframe\ulnone  to DataSet Conversion*********************//\cf0 \
    val Flight_Data_DS = Flight_Data_DF.as[Flight_Data1]\
    \cf4 //        ********Creation of Table*******************************//\cf0 \
    Flight_Data_DS.createOrReplaceTempView(\cf3 "Flight_Data"\cf0 )\
    val s = spark.sql(\cf3 "select * from Flight_Data1"\cf0 ).show(50, false)\
    \cf4 //****************The 3 airlines with the highest and lowest probability, respectively, for being \ul onschedule\ulnone *******************************//\cf0 \
  \}\
\}}